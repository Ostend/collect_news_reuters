# collect_news_reuters
collecting news articles/scrapping </br>
collects news from /world page of reuters. </br>
Columns: author, headline, article </br>
note: where author is [NONE] signifies it is 'Returers Staff"
### Output:

![df](https://user-images.githubusercontent.com/60686512/114020137-8976fb00-986f-11eb-8c35-9c166c77a964.PNG)
![df_console](https://user-images.githubusercontent.com/60686512/114020143-8b40be80-986f-11eb-99c3-48f49cd40750.PNG)

### To Do:
~~Figure out how to continuously loop to the next page.~~ <br>
~~clean up for loops~~ <br>
~~add headlines/author/date~~ <br>
~~clean up how the data is collected~~ <br>
~~format it as csv~~ 
- add date

- add more categories than world
