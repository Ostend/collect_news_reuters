# collect_news_reuters
collecting news articles/scrapping </br>
collects news from /world page of reuters. </br>
Columns: author, headline, article </br>
note: where author is [NONE] signifies it is 'Returers Staff"
### Output:
![df](https://user-images.githubusercontent.com/60686512/114003984-845d8000-985e-11eb-880a-a46d4da1c97f.PNG) 
![df_console](https://user-images.githubusercontent.com/60686512/114003991-858ead00-985e-11eb-9011-1ff1a458fb7c.PNG)

### To Do:
~~Figure out how to continuously loop to the next page.~~ <br>
~~clean up for loops~~ <br>
~~add headlines/author/date~~ <br>
~~clean up how the data is collected~~ <br>
~~format it as csv~~ 
- add date

- add more categories than world
